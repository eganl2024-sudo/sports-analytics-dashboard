{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 5: Feature Engineering\n",
    "\n",
    "**Goal:** Build ML-ready features from rolling team performance metrics with zero future leakage.\n",
    "\n",
    "| Step | Cell | Description |\n",
    "|------|------|-------------|\n",
    "| Setup | Cell 1 | Load continuous timeline (Master + banked + future) |\n",
    "| Unstack | Cell 2 | Convert matches to team-level records |\n",
    "| Rolling | Cell 3 | Calculate rolling features with shift(1) |\n",
    "| Matchup | Cell 4 | Map features back to match rows |\n",
    "| Split | Cell 5 | Re-split into 3 engineered CSVs |\n",
    "| Validate | Cell 6 | Leakage checks and feature summary |\n",
    "\n",
    "### Features Engineered\n",
    "| Feature | Window | Formula |\n",
    "|---------|--------|---------|\n",
    "| `form` | L5 / L10 | Rolling sum of points (W=3, D=1, L=0) |\n",
    "| `finishing_efficiency` | L5 / L10 | Rolling mean of (Goals - xG) |\n",
    "| `attacking_xg` | L5 / L10 | Rolling mean of xG created |\n",
    "| `defensive_xg` | L5 / L10 | Rolling mean of xG conceded |\n",
    "| `rest_days` | - | Days since previous match |\n",
    "\n",
    "### Anti-Leakage Design\n",
    "Every rolling feature uses `shift(1)` so match N uses only data from matches 1..N-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading continuous timeline...\n",
      "  Master (1415-2425):   19,837 rows\n",
      "  Banked (2526 played):  1,104 rows\n",
      "  Future (2526 sched):     648 rows\n",
      "\n",
      "Combined timeline: 21,589 rows\n",
      "  Date range: 2014-08-08 to 2026-12-04\n",
      "  Seasons: [1415, 1516, 1617, 1718, 1819, 1920, 2021, 2223, 2324, 2425, 2526]\n",
      "  Played: 20,941  |  Future: 648\n"
     ]
    }
   ],
   "source": [
    "# Ensure working directory is the project root perfectly across IDEs/Terminals\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    if 'notebooks' in os.getcwd():\n",
    "        project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    else:\n",
    "        project_root = os.getcwd()\n",
    "    os.chdir(project_root)\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.append(project_root)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =============================================================================\n",
    "# Cell 1: Setup & Load Continuous Timeline\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "processed_dir = os.path.join('data', 'processed')\n",
    "\n",
    "# --- Load all 3 CSVs ---\n",
    "print('Loading continuous timeline...')\n",
    "master = pd.read_csv(os.path.join(processed_dir, 'Master_Training_Set.csv'), low_memory=False)\n",
    "banked = pd.read_csv(os.path.join(processed_dir, 'current_season_banked.csv'), low_memory=False)\n",
    "future = pd.read_csv(os.path.join(processed_dir, 'future_schedule_features.csv'), low_memory=False)\n",
    "\n",
    "print(f'  Master (1415-2425):  {len(master):>7,} rows')\n",
    "print(f'  Banked (2526 played):{len(banked):>7,} rows')\n",
    "print(f'  Future (2526 sched): {len(future):>7,} rows')\n",
    "\n",
    "# --- Concat into one continuous timeline ---\n",
    "# Tag each row with its source for later re-splitting\n",
    "master['_source'] = 'history'\n",
    "banked['_source'] = 'banked'\n",
    "future['_source'] = 'future'\n",
    "\n",
    "timeline = pd.concat([master, banked, future], ignore_index=True)\n",
    "\n",
    "# --- Parse and sort by date ---\n",
    "timeline['date'] = pd.to_datetime(timeline['date_norm'], format='mixed', errors='coerce')\n",
    "timeline = timeline.sort_values(['date', 'league']).reset_index(drop=True)\n",
    "\n",
    "# --- Add a unique match ID for later joining ---\n",
    "timeline['_match_id'] = range(len(timeline))\n",
    "\n",
    "# --- Subset key columns ---\n",
    "key_cols = ['_match_id', '_source', 'league', 'season', 'date',\n",
    "            'home_team', 'away_team', 'FTHG', 'FTAG', 'FTR',\n",
    "            'home_xg', 'away_xg', 'home_elo', 'away_elo', 'elo_diff']\n",
    "slim = timeline[key_cols].copy()\n",
    "\n",
    "print(f'\\nCombined timeline: {len(slim):,} rows')\n",
    "print(f'  Date range: {slim[\"date\"].min().date()} to {slim[\"date\"].max().date()}')\n",
    "print(f'  Seasons: {sorted(slim[\"season\"].unique())}')\n",
    "print(f'  Played: {slim[\"FTR\"].notna().sum():,}  |  Future: {slim[\"FTR\"].isna().sum():,}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unstacking matches to team-level records...\n",
      "============================================================\n",
      "Team records: 43,178 rows (21,589 matches x 2 perspectives)\n",
      "Unique teams: 166\n",
      "\n",
      "Sample: Arsenal (last 6 matches)\n",
      "      date       opponent venue  gf  ga  xg_for  xg_against  points  excess_goals\n",
      "2026-04-18       Man City     A NaN NaN     NaN         NaN     NaN           NaN\n",
      "2026-04-25      Newcastle     H NaN NaN     NaN         NaN     NaN           NaN\n",
      "2026-05-17        Burnley     H NaN NaN     NaN         NaN     NaN           NaN\n",
      "2026-05-24 Crystal Palace     A NaN NaN     NaN         NaN     NaN           NaN\n",
      "2026-09-05       West Ham     A NaN NaN     NaN         NaN     NaN           NaN\n",
      "2026-11-04    Bournemouth     H NaN NaN     NaN         NaN     NaN           NaN\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Unstack Matches to Team-Level Records\n",
    "# =============================================================================\n",
    "# Each match produces TWO rows: one from home perspective, one from away.\n",
    "# This gives each team a chronological match log for rolling calculations.\n",
    "\n",
    "print('Unstacking matches to team-level records...')\n",
    "print('=' * 60)\n",
    "\n",
    "def make_team_records(df):\n",
    "    \"\"\"Convert match rows into team-perspective records.\"\"\"\n",
    "    # Home perspective\n",
    "    home = pd.DataFrame({\n",
    "        '_match_id': df['_match_id'],\n",
    "        'team': df['home_team'],\n",
    "        'opponent': df['away_team'],\n",
    "        'date': df['date'],\n",
    "        'venue': 'H',\n",
    "        'gf': df['FTHG'],\n",
    "        'ga': df['FTAG'],\n",
    "        'xg_for': df['home_xg'],\n",
    "        'xg_against': df['away_xg'],\n",
    "        'ftr': df['FTR'],\n",
    "        'league': df['league'],\n",
    "        'season': df['season'],\n",
    "        '_source': df['_source'],\n",
    "    })\n",
    "    \n",
    "    # Away perspective\n",
    "    away = pd.DataFrame({\n",
    "        '_match_id': df['_match_id'],\n",
    "        'team': df['away_team'],\n",
    "        'opponent': df['home_team'],\n",
    "        'date': df['date'],\n",
    "        'venue': 'A',\n",
    "        'gf': df['FTAG'],\n",
    "        'ga': df['FTHG'],\n",
    "        'xg_for': df['away_xg'],\n",
    "        'xg_against': df['home_xg'],\n",
    "        'ftr': df['FTR'],\n",
    "        'league': df['league'],\n",
    "        'season': df['season'],\n",
    "        '_source': df['_source'],\n",
    "    })\n",
    "    \n",
    "    records = pd.concat([home, away], ignore_index=True)\n",
    "    \n",
    "    # Calculate points from team's perspective\n",
    "    conditions = [\n",
    "        (records['venue'] == 'H') & (records['ftr'] == 'H'),  # Home win\n",
    "        (records['venue'] == 'A') & (records['ftr'] == 'A'),  # Away win\n",
    "        records['ftr'] == 'D',                                 # Draw\n",
    "    ]\n",
    "    records['points'] = np.select(conditions, [3, 3, 1], default=0)\n",
    "    \n",
    "    # For future games (no result), set points to NaN so they don't pollute rolling calcs\n",
    "    records.loc[records['ftr'].isna(), 'points'] = np.nan\n",
    "    \n",
    "    # Calculate excess goals (finishing efficiency raw)\n",
    "    records['excess_goals'] = records['gf'] - records['xg_for']\n",
    "    \n",
    "    # Sort chronologically per team\n",
    "    records = records.sort_values(['team', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    return records\n",
    "\n",
    "team_records = make_team_records(slim)\n",
    "\n",
    "print(f'Team records: {len(team_records):,} rows ({len(team_records)//2:,} matches x 2 perspectives)')\n",
    "print(f'Unique teams: {team_records[\"team\"].nunique()}')\n",
    "\n",
    "# Show sample for one team\n",
    "sample_team = 'Arsenal'\n",
    "sample = team_records[team_records['team'] == sample_team].tail(6)\n",
    "print(f'\\nSample: {sample_team} (last 6 matches)')\n",
    "print(sample[['date', 'opponent', 'venue', 'gf', 'ga', 'xg_for', 'xg_against', 'points', 'excess_goals']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing rolling features...\n",
      "============================================================\n",
      "Forward-fill: 3,686 NaN values filled with last known stats\n",
      "Rolling features calculated for 166 teams.\n",
      "\n",
      "Feature columns: ['form_l5', 'form_l10', 'finishing_efficiency_l5', 'finishing_efficiency_l10', 'attacking_xg_l5', 'attacking_xg_l10', 'defensive_xg_l5', 'defensive_xg_l10', 'rest_days']\n",
      "\n",
      "Sample: Arsenal (last 6 matches -- future games now have features)\n",
      "      date       opponent  points  form_l5  form_l10  finishing_efficiency_l5  finishing_efficiency_l10  attacking_xg_l5  attacking_xg_l10  defensive_xg_l5  defensive_xg_l10  rest_days\n",
      "2026-04-18       Man City     NaN      1.0       8.0                  0.21582                  0.038040          0.78418          1.961960          1.81154          0.675372       15.0\n",
      "2026-04-25      Newcastle     NaN      1.0       7.0                  0.21582                  0.763357          0.78418          1.736642          1.81154          0.764594        7.0\n",
      "2026-05-17        Burnley     NaN      1.0       7.0                  0.21582                  0.825847          0.78418          1.840820          1.81154          0.805825       22.0\n",
      "2026-05-24 Crystal Palace     NaN      1.0       4.0                  0.21582                  1.010905          0.78418          0.989095          1.81154          1.119382        7.0\n",
      "2026-09-05       West Ham     NaN      1.0       4.0                  0.21582                  1.010905          0.78418          0.989095          1.81154          1.119382      104.0\n",
      "2026-11-04    Bournemouth     NaN      1.0       1.0                  0.21582                  0.215820          0.78418          0.784180          1.81154          1.811540       60.0\n",
      "\n",
      "NaN rates (played):\n",
      "  form_l5                        NaN: 0.4%\n",
      "  form_l10                       NaN: 0.4%\n",
      "  finishing_efficiency_l5        NaN: 0.5%\n",
      "  finishing_efficiency_l10       NaN: 0.5%\n",
      "  attacking_xg_l5                NaN: 0.5%\n",
      "  attacking_xg_l10               NaN: 0.5%\n",
      "  defensive_xg_l5                NaN: 0.5%\n",
      "  defensive_xg_l10               NaN: 0.5%\n",
      "  rest_days                      NaN: 0.4%\n",
      "\n",
      "NaN rates (future):\n",
      "  form_l5                        NaN: 0.0%\n",
      "  form_l10                       NaN: 0.0%\n",
      "  finishing_efficiency_l5        NaN: 1.2%\n",
      "  finishing_efficiency_l10       NaN: 1.2%\n",
      "  attacking_xg_l5                NaN: 1.2%\n",
      "  attacking_xg_l10               NaN: 1.2%\n",
      "  defensive_xg_l5                NaN: 1.2%\n",
      "  defensive_xg_l10               NaN: 1.2%\n",
      "  rest_days                      NaN: 0.0%\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Calculate Rolling Features (Per Team)\n",
    "# =============================================================================\n",
    "# CRITICAL: shift(1) ensures no future leakage.\n",
    "# Match N's features use only data from matches 1..N-1.\n",
    "\n",
    "print('Computing rolling features...')\n",
    "print('=' * 60)\n",
    "\n",
    "def calc_rolling_features(group):\n",
    "    \"\"\"Calculate rolling features for a single team's chronological match log.\"\"\"\n",
    "    g = group.copy()\n",
    "    \n",
    "    for window in [5, 10]:\n",
    "        suffix = f'_l{window}'\n",
    "        \n",
    "        # Form: rolling SUM of points (shifted to prevent leakage)\n",
    "        g[f'form{suffix}'] = (\n",
    "            g['points']\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .sum()\n",
    "        )\n",
    "        \n",
    "        # Finishing Efficiency: rolling MEAN of excess_goals (Goals - xG)\n",
    "        g[f'finishing_efficiency{suffix}'] = (\n",
    "            g['excess_goals']\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "        )\n",
    "        \n",
    "        # Attacking Strength: rolling MEAN of xG created\n",
    "        g[f'attacking_xg{suffix}'] = (\n",
    "            g['xg_for']\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "        )\n",
    "        \n",
    "        # Defensive Strength: rolling MEAN of xG conceded\n",
    "        g[f'defensive_xg{suffix}'] = (\n",
    "            g['xg_against']\n",
    "            .shift(1)\n",
    "            .rolling(window=window, min_periods=1)\n",
    "            .mean()\n",
    "        )\n",
    "    \n",
    "    # Rest Days: days since previous match\n",
    "    g['rest_days'] = g['date'].diff().dt.days\n",
    "    \n",
    "    return g\n",
    "\n",
    "team_features = team_records.groupby('team', group_keys=False).apply(calc_rolling_features)\n",
    "team_features = team_features.reset_index(drop=True)\n",
    "\n",
    "# --- Feature columns ---\n",
    "feature_cols = [\n",
    "    'form_l5', 'form_l10',\n",
    "    'finishing_efficiency_l5', 'finishing_efficiency_l10',\n",
    "    'attacking_xg_l5', 'attacking_xg_l10',\n",
    "    'defensive_xg_l5', 'defensive_xg_l10',\n",
    "    'rest_days',\n",
    "]\n",
    "\n",
    "# --- Forward-fill: freeze rolling stats at last known values for future games ---\n",
    "# Without this, the 2nd+ future game per team gets NaN because the rolling\n",
    "# window starts including unplayed matches (NaN points/xG).\n",
    "# After ffill, every future fixture uses the team's most recent performance.\n",
    "before_null = team_features[feature_cols].isna().sum().sum()\n",
    "team_features[feature_cols] = (\n",
    "    team_features\n",
    "    .groupby('team')[feature_cols]\n",
    "    .ffill()\n",
    ")\n",
    "after_null = team_features[feature_cols].isna().sum().sum()\n",
    "print(f'Forward-fill: {before_null - after_null:,} NaN values filled with last known stats')\n",
    "\n",
    "print(f'Rolling features calculated for {team_features[\"team\"].nunique()} teams.')\n",
    "print(f'\\nFeature columns: {feature_cols}')\n",
    "\n",
    "# --- Show sample ---\n",
    "sample = team_features[team_features['team'] == 'Arsenal'].tail(6)\n",
    "print(f'\\nSample: Arsenal (last 6 matches -- future games now have features)')\n",
    "print(sample[['date', 'opponent', 'points'] + feature_cols].to_string(index=False))\n",
    "\n",
    "# --- Check for NaN in features ---\n",
    "played_features = team_features[team_features['_source'] != 'future']\n",
    "future_features = team_features[team_features['_source'] == 'future']\n",
    "print(f'\\nNaN rates (played):')\n",
    "for col in feature_cols:\n",
    "    null_pct = played_features[col].isna().mean() * 100\n",
    "    print(f'  {col:30s} NaN: {null_pct:.1f}%')\n",
    "print(f'\\nNaN rates (future):')\n",
    "for col in feature_cols:\n",
    "    null_pct = future_features[col].isna().mean() * 100\n",
    "    print(f'  {col:30s} NaN: {null_pct:.1f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping rolling features to match rows...\n",
      "============================================================\n",
      "Matchup dataset: 21,589 rows x 37 columns\n",
      "New feature columns: 23\n",
      "\n",
      "Feature list:\n",
      "   1. home_form_l5                        NaN:   0.4%\n",
      "   2. home_form_l10                       NaN:   0.4%\n",
      "   3. home_finishing_efficiency_l5        NaN:   0.4%\n",
      "   4. home_finishing_efficiency_l10       NaN:   0.4%\n",
      "   5. home_attacking_xg_l5                NaN:   0.4%\n",
      "   6. home_attacking_xg_l10               NaN:   0.4%\n",
      "   7. home_defensive_xg_l5                NaN:   0.4%\n",
      "   8. home_defensive_xg_l10               NaN:   0.4%\n",
      "   9. home_rest_days                      NaN:   0.4%\n",
      "  10. away_form_l5                        NaN:   0.4%\n",
      "  11. away_form_l10                       NaN:   0.4%\n",
      "  12. away_finishing_efficiency_l5        NaN:   0.5%\n",
      "  13. away_finishing_efficiency_l10       NaN:   0.5%\n",
      "  14. away_attacking_xg_l5                NaN:   0.5%\n",
      "  15. away_attacking_xg_l10               NaN:   0.5%\n",
      "  16. away_defensive_xg_l5                NaN:   0.5%\n",
      "  17. away_defensive_xg_l10               NaN:   0.5%\n",
      "  18. away_rest_days                      NaN:   0.4%\n",
      "  19. form_diff_l5                        NaN:   0.5%\n",
      "  20. form_diff_l10                       NaN:   0.5%\n",
      "  21. attack_vs_defense_l5                NaN:   0.7%\n",
      "  22. defense_vs_attack_l5                NaN:   0.7%\n",
      "  23. elo_diff                            NaN:   1.7%\n",
      "\n",
      "Sample matchup (last 3 history rows):\n",
      "home_team  away_team FTR    elo_diff  home_form_l5  away_form_l5  home_finishing_efficiency_l5  away_finishing_efficiency_l5\n",
      "   Torino       Roma   A -127.730225           4.0          12.0                     -0.519681                     -0.039082\n",
      "  Udinese Fiorentina   A -124.736450           4.0           9.0                     -0.414869                      0.691647\n",
      "  Venezia   Juventus   A -240.895874           5.0           8.0                     -0.319744                     -0.079613\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Map Features Back to Match Rows (The \"Matchup\" Dataset)\n",
    "# =============================================================================\n",
    "# Join home team's rolling stats as home_*, away team's as away_*.\n",
    "\n",
    "print('Mapping rolling features to match rows...')\n",
    "print('=' * 60)\n",
    "\n",
    "# Separate home and away features from team_features\n",
    "home_feats = team_features[team_features['venue'] == 'H'][['_match_id'] + feature_cols].copy()\n",
    "away_feats = team_features[team_features['venue'] == 'A'][['_match_id'] + feature_cols].copy()\n",
    "\n",
    "# Rename with home_ / away_ prefix\n",
    "home_feats = home_feats.rename(columns={c: f'home_{c}' for c in feature_cols})\n",
    "away_feats = away_feats.rename(columns={c: f'away_{c}' for c in feature_cols})\n",
    "\n",
    "# Join back to the original timeline\n",
    "matchup = slim.merge(home_feats, on='_match_id', how='left')\n",
    "matchup = matchup.merge(away_feats, on='_match_id', how='left')\n",
    "\n",
    "# --- Derived matchup features ---\n",
    "matchup['form_diff_l5'] = matchup['home_form_l5'] - matchup['away_form_l5']\n",
    "matchup['form_diff_l10'] = matchup['home_form_l10'] - matchup['away_form_l10']\n",
    "matchup['attack_vs_defense_l5'] = matchup['home_attacking_xg_l5'] - matchup['away_defensive_xg_l5']\n",
    "matchup['defense_vs_attack_l5'] = matchup['home_defensive_xg_l5'] - matchup['away_attacking_xg_l5']\n",
    "\n",
    "# --- Summary ---\n",
    "all_feature_cols = (\n",
    "    [f'home_{c}' for c in feature_cols] +\n",
    "    [f'away_{c}' for c in feature_cols] +\n",
    "    ['form_diff_l5', 'form_diff_l10', 'attack_vs_defense_l5', 'defense_vs_attack_l5', 'elo_diff']\n",
    ")\n",
    "\n",
    "print(f'Matchup dataset: {len(matchup):,} rows x {len(matchup.columns)} columns')\n",
    "print(f'New feature columns: {len(all_feature_cols)}')\n",
    "print(f'\\nFeature list:')\n",
    "for i, col in enumerate(all_feature_cols, 1):\n",
    "    null_pct = matchup[col].isna().mean() * 100\n",
    "    print(f'  {i:2d}. {col:35s} NaN: {null_pct:5.1f}%')\n",
    "\n",
    "# --- Quick sample ---\n",
    "print(f'\\nSample matchup (last 3 history rows):')\n",
    "sample = matchup[matchup['_source'] == 'history'].tail(3)\n",
    "print(sample[['home_team', 'away_team', 'FTR', 'elo_diff', 'home_form_l5', 'away_form_l5', 'home_finishing_efficiency_l5', 'away_finishing_efficiency_l5']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-splitting into 3 engineered datasets...\n",
      "============================================================\n",
      "  [A] model_training_engineered.csv:   19,837 rows -> data\\processed\\model_training_engineered.csv\n",
      "  [B] current_banked_engineered.csv:    1,104 rows -> data\\processed\\current_banked_engineered.csv\n",
      "  [C] future_predict_engineered.csv:      648 rows -> data\\processed\\future_predict_engineered.csv\n",
      "\n",
      "  Total: 21,589 rows (should match timeline: 21,589)\n",
      "  training         7252 KB\n",
      "  banked            413 KB\n",
      "  future            210 KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Re-Split into 3 Engineered CSVs\n",
    "# =============================================================================\n",
    "\n",
    "print('Re-splitting into 3 engineered datasets...')\n",
    "print('=' * 60)\n",
    "\n",
    "# Drop internal columns before saving\n",
    "save_cols = [c for c in matchup.columns if not c.startswith('_')]\n",
    "clean = matchup[save_cols].copy()\n",
    "\n",
    "# --- File A: model_training_engineered.csv (all history) ---\n",
    "train_eng = clean[matchup['_source'] == 'history'].copy()\n",
    "train_path = os.path.join(processed_dir, 'model_training_engineered.csv')\n",
    "train_eng.to_csv(train_path, index=False)\n",
    "print(f'  [A] model_training_engineered.csv:  {len(train_eng):>7,} rows -> {train_path}')\n",
    "\n",
    "# --- File B: current_banked_engineered.csv (25/26 played) ---\n",
    "banked_eng = clean[matchup['_source'] == 'banked'].copy()\n",
    "banked_path = os.path.join(processed_dir, 'current_banked_engineered.csv')\n",
    "banked_eng.to_csv(banked_path, index=False)\n",
    "print(f'  [B] current_banked_engineered.csv:  {len(banked_eng):>7,} rows -> {banked_path}')\n",
    "\n",
    "# --- File C: future_predict_engineered.csv (25/26 upcoming) ---\n",
    "future_eng = clean[matchup['_source'] == 'future'].copy()\n",
    "future_path = os.path.join(processed_dir, 'future_predict_engineered.csv')\n",
    "future_eng.to_csv(future_path, index=False)\n",
    "print(f'  [C] future_predict_engineered.csv:  {len(future_eng):>7,} rows -> {future_path}')\n",
    "\n",
    "# --- Row count validation ---\n",
    "total = len(train_eng) + len(banked_eng) + len(future_eng)\n",
    "print(f'\\n  Total: {total:,} rows (should match timeline: {len(matchup):,})')\n",
    "\n",
    "# --- File sizes ---\n",
    "for name, path in [('training', train_path), ('banked', banked_path), ('future', future_path)]:\n",
    "    size_kb = os.path.getsize(path) / 1024\n",
    "    print(f'  {name:12s} {size_kb:>8.0f} KB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PHASE 5 VALIDATION\n",
      "============================================================\n",
      "\n",
      "  1. finishing_efficiency_l5 exists:  [PASS]\n",
      "  2. No future leakage (Liverpool):   [PASS]\n",
      "  3. Future features coverage:       [PASS] (97.5%)\n",
      "  4. All feature cols in outputs:    [PASS]\n",
      "  5. Row counts match originals:     [PASS]\n",
      "     Training: 19,837 (was 19,837)\n",
      "     Banked:   1,104 (was 1,104)\n",
      "     Future:   648 (was 648)\n",
      "\n",
      "  Feature Statistics (Training Set):\n",
      "  Feature                                 Mean      Std      Min      Max\n",
      "  ---------------------------------------------------------------------\n",
      "  home_form_l5                            6.73     3.60     0.00    15.00\n",
      "  away_form_l5                            6.93     3.61     0.00    15.00\n",
      "  home_finishing_efficiency_l5            0.00     0.48    -2.35     2.79\n",
      "  away_finishing_efficiency_l5            0.00     0.49    -2.19     2.73\n",
      "  elo_diff                                0.21   160.18  -530.86   518.48\n",
      "  home_rest_days                         10.57    44.81     0.00  2640.00\n",
      "  away_rest_days                         10.73    47.11     0.00  2283.00\n",
      "\n",
      "============================================================\n",
      "Phase 5 complete. Engineered features are ready for modeling.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Validation & Sanity Checks\n",
    "# =============================================================================\n",
    "\n",
    "print('PHASE 5 VALIDATION')\n",
    "print('=' * 60)\n",
    "\n",
    "# --- Check 1: finishing_efficiency_l5 exists ---\n",
    "fe_exists = 'home_finishing_efficiency_l5' in train_eng.columns and 'away_finishing_efficiency_l5' in train_eng.columns\n",
    "print(f'\\n  1. finishing_efficiency_l5 exists:  {\"[PASS]\" if fe_exists else \"[FAIL]\"}')\n",
    "\n",
    "# --- Check 2: No future leakage test ---\n",
    "# For a played match, verify the rolling features were computed BEFORE that match.\n",
    "# We do this by checking that team_features shift(1) is correctly applied:\n",
    "# Pick a team, look at match N, and verify form_l5 equals sum of points from matches N-5..N-1\n",
    "test_team = 'Liverpool'\n",
    "test_records = team_features[\n",
    "    (team_features['team'] == test_team) & \n",
    "    (team_features['_source'] != 'future')\n",
    "].copy()\n",
    "\n",
    "if len(test_records) >= 10:\n",
    "    # Check match at index 10 (0-indexed)\n",
    "    test_idx = 10\n",
    "    test_row = test_records.iloc[test_idx]\n",
    "    prev_5_pts = test_records.iloc[test_idx-5:test_idx]['points'].sum()\n",
    "    computed_form = test_row['form_l5']\n",
    "    leakage_pass = abs(computed_form - prev_5_pts) < 0.01\n",
    "    print(f'  2. No future leakage ({test_team}):   {\"[PASS]\" if leakage_pass else \"[FAIL]\"}')\n",
    "    if not leakage_pass:\n",
    "        print(f'     Expected form_l5={prev_5_pts}, got {computed_form}')\n",
    "else:\n",
    "    print(f'  2. No future leakage:              [SKIP] (not enough data for {test_team})')\n",
    "\n",
    "# --- Check 3: Future fixtures have valid rolling stats ---\n",
    "future_check = future_eng[['home_form_l5', 'away_form_l5', 'home_attacking_xg_l5', 'away_attacking_xg_l5']]\n",
    "future_coverage = future_check.notna().all(axis=1).mean() * 100\n",
    "future_ok = future_coverage > 90\n",
    "print(f'  3. Future features coverage:       {\"[PASS]\" if future_ok else \"[WARN]\"} ({future_coverage:.1f}%)')\n",
    "\n",
    "# --- Check 4: All 3 files have feature columns ---\n",
    "required_features = ['home_form_l5', 'away_form_l5', 'home_finishing_efficiency_l5',\n",
    "                     'away_finishing_efficiency_l5', 'elo_diff', 'home_rest_days', 'away_rest_days']\n",
    "all_present = all(c in train_eng.columns and c in future_eng.columns for c in required_features)\n",
    "print(f'  4. All feature cols in outputs:    {\"[PASS]\" if all_present else \"[FAIL]\"}')\n",
    "\n",
    "# --- Check 5: Row counts match original ---\n",
    "rows_ok = len(train_eng) == len(master) and len(banked_eng) == len(banked) and len(future_eng) == len(future)\n",
    "print(f'  5. Row counts match originals:     {\"[PASS]\" if rows_ok else \"[WARN]\"}')\n",
    "print(f'     Training: {len(train_eng):,} (was {len(master):,})')\n",
    "print(f'     Banked:   {len(banked_eng):,} (was {len(banked):,})')\n",
    "print(f'     Future:   {len(future_eng):,} (was {len(future):,})')\n",
    "\n",
    "# --- Feature summary statistics ---\n",
    "print(f'\\n  Feature Statistics (Training Set):')\n",
    "print(f'  {\"Feature\":35s} {\"Mean\":>8s} {\"Std\":>8s} {\"Min\":>8s} {\"Max\":>8s}')\n",
    "print(f'  {\"-\"*69}')\n",
    "for col in required_features:\n",
    "    if col in train_eng.columns:\n",
    "        s = train_eng[col].dropna()\n",
    "        print(f'  {col:35s} {s.mean():8.2f} {s.std():8.2f} {s.min():8.2f} {s.max():8.2f}')\n",
    "\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "print('Phase 5 complete. Engineered features are ready for modeling.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}