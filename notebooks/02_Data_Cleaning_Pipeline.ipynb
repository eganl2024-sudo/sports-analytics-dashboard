{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning Pipeline - Phase 2: The Rosetta Stone\n",
    "\n",
    "**Goal:** Merge MatchHistory, Understat, and ClubElo into a single Master Training Set.\n",
    "\n",
    "| Step | Description |\n",
    "|------|-------------|\n",
    "| Cell 1 | Setup, load raw data, define team name mappings |\n",
    "| Cell 2 | Apply mappings and validate team alignment |\n",
    "| Cell 3 | Merge MatchHistory + Understat (on date + home/away teams) |\n",
    "| Cell 4 | Merge ClubElo (nearest-date Elo lookup for home and away) |\n",
    "| Cell 5 | Validation and quality checks |\n",
    "| Cell 6 | Save Master_Training_Set.csv |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MatchHistory data...\n",
      "  ENG_Premier_League_MatchHistory.csv            4180 rows\n",
      "  ESP_La_Liga_MatchHistory.csv                   4180 rows\n",
      "  FRA_Ligue_1_MatchHistory.csv                   3931 rows\n",
      "  GER_Bundesliga_MatchHistory.csv                3366 rows\n",
      "  ITA_Serie_A_MatchHistory.csv                   4180 rows\n",
      "  Total MatchHistory: 19,837 rows\n",
      "\n",
      "Loading Understat data...\n",
      "  ENG_Premier_League_Understat.csv               4180 rows\n",
      "  ESP_La_Liga_Understat.csv                      4180 rows\n",
      "  FRA_Ligue_1_Understat.csv                      4032 rows\n",
      "  GER_Bundesliga_Understat.csv                   3366 rows\n",
      "  ITA_Serie_A_Understat.csv                      4180 rows\n",
      "  Total Understat: 19,938 rows\n",
      "\n",
      "Loading ClubElo data...\n",
      "  ClubElo: 699,162 rows, 161 unique teams\n",
      "\n",
      "Mappings loaded: 42 Understat, 17 ClubElo\n",
      "Setup complete.\n"
     ]
    }
   ],
   "source": [
    "# Ensure working directory is the project root perfectly across IDEs/Terminals\n",
    "import os\n",
    "import sys\n",
    "try:\n",
    "    if 'notebooks' in os.getcwd():\n",
    "        project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "    else:\n",
    "        project_root = os.getcwd()\n",
    "    os.chdir(project_root)\n",
    "    if project_root not in sys.path:\n",
    "        sys.path.append(project_root)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# =============================================================================\n",
    "# Cell 1: Setup, Load Raw Data, Define Team Name Mappings\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "raw_dir = os.path.join('data', 'raw')\n",
    "processed_dir = os.path.join('data', 'processed')\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# --- Load all MatchHistory files into one DataFrame ---\n",
    "print('Loading MatchHistory data...')\n",
    "mh_files = sorted(glob.glob(os.path.join(raw_dir, '*_MatchHistory.csv')))\n",
    "mh_frames = []\n",
    "for f in mh_files:\n",
    "    df = pd.read_csv(f)\n",
    "    mh_frames.append(df)\n",
    "    print(f'  {os.path.basename(f):45s} {len(df):>5} rows')\n",
    "mh_all = pd.concat(mh_frames, ignore_index=True)\n",
    "print(f'  Total MatchHistory: {len(mh_all):,} rows')\n",
    "\n",
    "# --- Load all Understat files into one DataFrame ---\n",
    "print('\\nLoading Understat data...')\n",
    "us_files = sorted(glob.glob(os.path.join(raw_dir, '*_Understat.csv')))\n",
    "us_frames = []\n",
    "for f in us_files:\n",
    "    df = pd.read_csv(f)\n",
    "    us_frames.append(df)\n",
    "    print(f'  {os.path.basename(f):45s} {len(df):>5} rows')\n",
    "us_all = pd.concat(us_frames, ignore_index=True)\n",
    "print(f'  Total Understat: {len(us_all):,} rows')\n",
    "\n",
    "# --- Load ClubElo ---\n",
    "print('\\nLoading ClubElo data...')\n",
    "elo_all = pd.read_csv(os.path.join(raw_dir, 'ClubElo_Master.csv'))\n",
    "print(f'  ClubElo: {len(elo_all):,} rows, {elo_all[\"team\"].nunique()} unique teams')\n",
    "\n",
    "# =========================================================================\n",
    "# TEAM NAME MAPPINGS\n",
    "# All names are standardized TO MatchHistory format (our source of truth).\n",
    "# =========================================================================\n",
    "\n",
    "# --- Understat -> MatchHistory ---\n",
    "understat_to_mh = {\n",
    "    # ENG - Premier League\n",
    "    'Manchester City':           'Man City',\n",
    "    'Manchester United':         'Man United',\n",
    "    'Newcastle United':          'Newcastle',\n",
    "    'Nottingham Forest':         \"Nott'm Forest\",\n",
    "    'West Bromwich Albion':      'West Brom',\n",
    "    'Wolverhampton Wanderers':   'Wolves',\n",
    "    'Queens Park Rangers':       'QPR',\n",
    "    # ESP - La Liga\n",
    "    'Athletic Club':             'Ath Bilbao',\n",
    "    'Atletico Madrid':           'Ath Madrid',\n",
    "    'Real Betis':                'Betis',\n",
    "    'Celta Vigo':                'Celta',\n",
    "    'Espanyol':                  'Espanol',\n",
    "    'SD Huesca':                 'Huesca',\n",
    "    'Deportivo La Coruna':       'La Coruna',\n",
    "    'Real Sociedad':             'Sociedad',\n",
    "    'Sporting Gijon':            'Sp Gijon',\n",
    "    'Real Valladolid':           'Valladolid',\n",
    "    'Rayo Vallecano':            'Vallecano',\n",
    "    # GER - Bundesliga\n",
    "    'Arminia Bielefeld':         'Bielefeld',\n",
    "    'Borussia Dortmund':         'Dortmund',\n",
    "    'Eintracht Frankfurt':       'Ein Frankfurt',\n",
    "    'FC Cologne':                'FC Koln',\n",
    "    'Fortuna Duesseldorf':       'Fortuna Dusseldorf',\n",
    "    'Hamburger SV':              'Hamburg',\n",
    "    'Hannover 96':               'Hannover',\n",
    "    'FC Heidenheim':             'Heidenheim',\n",
    "    'Hertha Berlin':             'Hertha',\n",
    "    'Bayer Leverkusen':          'Leverkusen',\n",
    "    'Borussia M.Gladbach':       \"M'gladbach\",\n",
    "    'Mainz 05':                  'Mainz',\n",
    "    'Nuernberg':                 'Nurnberg',\n",
    "    'RasenBallsport Leipzig':    'RB Leipzig',\n",
    "    'St. Pauli':                 'St Pauli',\n",
    "    'VfB Stuttgart':             'Stuttgart',\n",
    "    # ITA - Serie A\n",
    "    'AC Milan':                  'Milan',\n",
    "    'SPAL 2013':                 'Spal',\n",
    "    'Parma Calcio 1913':         'Parma',\n",
    "    # FRA - Ligue 1\n",
    "    'GFC Ajaccio':               'Ajaccio GFCO',\n",
    "    'SC Bastia':                 'Bastia',\n",
    "    'Clermont Foot':             'Clermont',\n",
    "    'Paris Saint Germain':       'Paris SG',\n",
    "    'Saint-Etienne':             'St Etienne',\n",
    "}\n",
    "\n",
    "# --- ClubElo -> MatchHistory ---\n",
    "clubelo_to_mh = {\n",
    "    'Atletico':          'Ath Madrid',\n",
    "    'Bilbao':            'Ath Bilbao',\n",
    "    'Bayern':            'Bayern Munich',\n",
    "    'Frankfurt':         'Ein Frankfurt',\n",
    "    'Espanyol':          'Espanol',\n",
    "    'Gladbach':          \"M'gladbach\",\n",
    "    'Forest':            \"Nott'm Forest\",\n",
    "    'Koeln':             'FC Koln',\n",
    "    'Duesseldorf':       'Fortuna Dusseldorf',\n",
    "    'Holstein':          'Holstein Kiel',\n",
    "    'Depor':             'La Coruna',\n",
    "    'Nuernberg':         'Nurnberg',\n",
    "    'Gijon':             'Sp Gijon',\n",
    "    'Rayo Vallecano':    'Vallecano',\n",
    "    'Werder':            'Werder Bremen',\n",
    "    'Evian TG':          'Evian Thonon Gaillard',\n",
    "    'Schalke':           'Schalke 04',\n",
    "}\n",
    "\n",
    "print(f'\\nMappings loaded: {len(understat_to_mh)} Understat, {len(clubelo_to_mh)} ClubElo')\n",
    "print('Setup complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying Understat name mappings...\n",
      "Applying ClubElo name mappings...\n",
      "\n",
      "--- Post-Mapping Orphan Check ---\n",
      "  MH teams total: 163\n",
      "  Understat team names: 163\n",
      "  ClubElo teams: 161\n",
      "\n",
      "  [OK] All MH teams found in Understat\n",
      "\n",
      "  [WARN] 2 MH teams still missing from ClubElo:\n",
      "    - Ajaccio GFCO\n",
      "    - St Etienne\n",
      "\n",
      "Name alignment complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 2: Apply Name Mappings & Validate Team Alignment\n",
    "# =============================================================================\n",
    "\n",
    "# --- Apply Understat mappings ---\n",
    "print('Applying Understat name mappings...')\n",
    "us_all['home_team'] = us_all['home_team'].replace(understat_to_mh)\n",
    "us_all['away_team'] = us_all['away_team'].replace(understat_to_mh)\n",
    "\n",
    "# --- Apply ClubElo mappings ---\n",
    "print('Applying ClubElo name mappings...')\n",
    "elo_all['team'] = elo_all['team'].replace(clubelo_to_mh)\n",
    "\n",
    "# --- Validation: check orphans after mapping ---\n",
    "mh_teams = set(mh_all['home_team'].dropna().unique()) | set(mh_all['away_team'].dropna().unique())\n",
    "us_teams = set(us_all['home_team'].dropna().unique()) | set(us_all['away_team'].dropna().unique())\n",
    "elo_teams = set(str(t) for t in elo_all['team'].dropna().unique())\n",
    "\n",
    "# Filter out team codes (3-letter) and IDs (numeric) from Understat, but keep ones matching MH\n",
    "us_team_names = {t for t in us_teams if (len(str(t)) > 3 and not str(t).isdigit()) or t in mh_teams}\n",
    "\n",
    "mh_not_us = sorted(mh_teams - us_team_names)\n",
    "mh_not_elo = sorted(mh_teams - elo_teams)\n",
    "\n",
    "print(f'\\n--- Post-Mapping Orphan Check ---')\n",
    "print(f'  MH teams total: {len(mh_teams)}')\n",
    "print(f'  Understat team names: {len(us_team_names)}')\n",
    "print(f'  ClubElo teams: {len(elo_teams)}')\n",
    "\n",
    "if mh_not_us:\n",
    "    print(f'\\n  [WARN] {len(mh_not_us)} MH teams still missing from Understat:')\n",
    "    for t in mh_not_us:\n",
    "        print(f'    - {t}')\n",
    "else:\n",
    "    print(f'\\n  [OK] All MH teams found in Understat')\n",
    "\n",
    "if mh_not_elo:\n",
    "    print(f'\\n  [WARN] {len(mh_not_elo)} MH teams still missing from ClubElo:')\n",
    "    for t in mh_not_elo:\n",
    "        print(f'    - {t}')\n",
    "else:\n",
    "    print(f'\\n  [OK] All MH teams found in ClubElo')\n",
    "\n",
    "print('\\nName alignment complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for merge...\n",
      "  Understat merge-ready: 18,112 rows\n",
      "Merging MatchHistory + Understat on [date, home_team, away_team]...\n",
      "\n",
      "  Total rows: 19,837\n",
      "  xG matched: 19,694 / 19,837 (99.3%)\n",
      "  xG missing: 143 (0.7%)\n",
      "\n",
      "  Per-league xG match rates:\n",
      "    [OK]   ENG-Premier League         4154/ 4180 (99.4%)\n",
      "    [OK]   ESP-La Liga                4112/ 4180 (98.4%)\n",
      "    [OK]   FRA-Ligue 1                3896/ 3931 (99.1%)\n",
      "    [OK]   GER-Bundesliga             3365/ 3366 (100.0%)\n",
      "    [OK]   ITA-Serie A                4167/ 4180 (99.7%)\n",
      "\n",
      "MH + Understat merge complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 3: Merge MatchHistory + Understat\n",
    "# =============================================================================\n",
    "\n",
    "print('Preparing data for merge...')\n",
    "\n",
    "# --- Normalize dates to YYYY-MM-DD for both datasets ---\n",
    "mh_all['date_norm'] = pd.to_datetime(mh_all['date'], format='mixed').dt.date\n",
    "us_all['date_norm'] = pd.to_datetime(us_all['date'], format='mixed').dt.date\n",
    "\n",
    "# --- Select key columns from Understat ---\n",
    "us_cols = ['date_norm', 'home_team', 'away_team', 'home_xg', 'away_xg']\n",
    "us_merge = us_all[us_cols].copy()\n",
    "\n",
    "# --- Drop duplicate Understat rows (same date + teams) ---\n",
    "us_merge = us_merge.drop_duplicates(subset=['date_norm', 'home_team', 'away_team'])\n",
    "print(f'  Understat merge-ready: {len(us_merge):,} rows')\n",
    "\n",
    "# --- Merge ---\n",
    "print('Merging MatchHistory + Understat on [date, home_team, away_team]...')\n",
    "merged = mh_all.merge(\n",
    "    us_merge,\n",
    "    on=['date_norm', 'home_team', 'away_team'],\n",
    "    how='left',\n",
    "    suffixes=('', '_us')\n",
    ")\n",
    "\n",
    "# --- Report merge quality ---\n",
    "xg_matched = merged['home_xg'].notna().sum()\n",
    "xg_pct = xg_matched / len(merged) * 100\n",
    "print(f'\\n  Total rows: {len(merged):,}')\n",
    "print(f'  xG matched: {xg_matched:,} / {len(merged):,} ({xg_pct:.1f}%)')\n",
    "print(f'  xG missing: {merged[\"home_xg\"].isna().sum():,} ({100-xg_pct:.1f}%)')\n",
    "\n",
    "# --- Per-league breakdown ---\n",
    "print(f'\\n  Per-league xG match rates:')\n",
    "for league in sorted(merged['league'].unique()):\n",
    "    mask = merged['league'] == league\n",
    "    total = mask.sum()\n",
    "    matched = merged.loc[mask, 'home_xg'].notna().sum()\n",
    "    pct = matched / total * 100 if total > 0 else 0\n",
    "    status = '[OK]  ' if pct >= 95 else '[WARN]'\n",
    "    print(f'    {status} {league:25s} {matched:>5}/{total:>5} ({pct:.1f}%)')\n",
    "\n",
    "print('\\nMH + Understat merge complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing ClubElo data for nearest-date merge...\n",
      "  ClubElo records after cleaning: 699,162\n",
      "Looking up Home team Elo ratings...\n",
      "Looking up Away team Elo ratings...\n",
      "\n",
      "  Home Elo matched: 19,654 / 19,837 (99.1%)\n",
      "  Away Elo matched: 19,654 / 19,837\n",
      "  Elo missing: 183 (0.9%)\n",
      "\n",
      "  Per-league Elo match rates:\n",
      "    [OK]   ENG-Premier League         4180/ 4180 (100.0%)\n",
      "    [OK]   ESP-La Liga                4180/ 4180 (100.0%)\n",
      "    [OK]   FRA-Ligue 1                3748/ 3931 (95.3%)\n",
      "    [OK]   GER-Bundesliga             3366/ 3366 (100.0%)\n",
      "    [OK]   ITA-Serie A                4180/ 4180 (100.0%)\n",
      "\n",
      "ClubElo merge complete.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 4: Merge ClubElo (Nearest-Date Elo Lookup)\n",
    "# =============================================================================\n",
    "\n",
    "print('Preparing ClubElo data for nearest-date merge...')\n",
    "\n",
    "# --- Parse the ClubElo date column ---\n",
    "# ClubElo has a 'to' column = end date of that Elo rating period\n",
    "elo_all['elo_date'] = pd.to_datetime(elo_all['to'], format='mixed', errors='coerce')\n",
    "elo_clean = elo_all.dropna(subset=['elo_date', 'team', 'elo']).copy()\n",
    "elo_clean = elo_clean[['team', 'elo_date', 'elo']].copy()\n",
    "elo_clean = elo_clean.sort_values('elo_date').reset_index(drop=True)\n",
    "print(f'  ClubElo records after cleaning: {len(elo_clean):,}')\n",
    "\n",
    "# --- Convert match dates for merge_asof ---\n",
    "merged['match_date'] = pd.to_datetime(merged['date_norm'])\n",
    "\n",
    "# --- Home Elo lookup ---\n",
    "print('Looking up Home team Elo ratings...')\n",
    "home_df = merged[['match_date', 'home_team']].copy()\n",
    "home_df = home_df.rename(columns={'home_team': 'team'})\n",
    "home_df = home_df.sort_values('match_date').reset_index()\n",
    "\n",
    "home_elo = pd.merge_asof(\n",
    "    home_df,\n",
    "    elo_clean.rename(columns={'elo': 'home_elo'}),\n",
    "    left_on='match_date',\n",
    "    right_on='elo_date',\n",
    "    by='team',\n",
    "    direction='backward'\n",
    ")\n",
    "home_elo = home_elo.set_index('index')['home_elo']\n",
    "merged['home_elo'] = home_elo\n",
    "\n",
    "# --- Away Elo lookup ---\n",
    "print('Looking up Away team Elo ratings...')\n",
    "away_df = merged[['match_date', 'away_team']].copy()\n",
    "away_df = away_df.rename(columns={'away_team': 'team'})\n",
    "away_df = away_df.sort_values('match_date').reset_index()\n",
    "\n",
    "away_elo = pd.merge_asof(\n",
    "    away_df,\n",
    "    elo_clean.rename(columns={'elo': 'away_elo'}),\n",
    "    left_on='match_date',\n",
    "    right_on='elo_date',\n",
    "    by='team',\n",
    "    direction='backward'\n",
    ")\n",
    "away_elo = away_elo.set_index('index')['away_elo']\n",
    "merged['away_elo'] = away_elo\n",
    "\n",
    "# --- Derived feature ---\n",
    "merged['elo_diff'] = merged['home_elo'] - merged['away_elo']\n",
    "\n",
    "# --- Report ---\n",
    "elo_matched = merged['home_elo'].notna().sum()\n",
    "elo_pct = elo_matched / len(merged) * 100\n",
    "print(f'\\n  Home Elo matched: {elo_matched:,} / {len(merged):,} ({elo_pct:.1f}%)')\n",
    "print(f'  Away Elo matched: {merged[\"away_elo\"].notna().sum():,} / {len(merged):,}')\n",
    "print(f'  Elo missing: {merged[\"home_elo\"].isna().sum():,} ({100-elo_pct:.1f}%)')\n",
    "\n",
    "# --- Per-league breakdown ---\n",
    "print(f'\\n  Per-league Elo match rates:')\n",
    "for league in sorted(merged['league'].unique()):\n",
    "    mask = merged['league'] == league\n",
    "    total = mask.sum()\n",
    "    matched = merged.loc[mask, 'home_elo'].notna().sum()\n",
    "    pct = matched / total * 100 if total > 0 else 0\n",
    "    status = '[OK]  ' if pct >= 95 else '[WARN]'\n",
    "    print(f'    {status} {league:25s} {matched:>5}/{total:>5} ({pct:.1f}%)')\n",
    "\n",
    "# --- Drop helper columns ---\n",
    "merged = merged.drop(columns=['match_date'], errors='ignore')\n",
    "\n",
    "print('\\nClubElo merge complete.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASTER DATASET VALIDATION\n",
      "============================================================\n",
      "\n",
      "  Missingness check (threshold: <5%):\n",
      "    [PASS] home_xg            143 missing (0.72%)\n",
      "    [PASS] away_xg            143 missing (0.72%)\n",
      "    [PASS] home_elo           183 missing (0.92%)\n",
      "    [PASS] away_elo           183 missing (0.92%)\n",
      "    [PASS] elo_diff           364 missing (1.83%)\n",
      "\n",
      "  League coverage:\n",
      "    ENG-Premier League         4180 rows, 10 seasons\n",
      "    ESP-La Liga                4180 rows, 10 seasons\n",
      "    FRA-Ligue 1                3931 rows, 10 seasons\n",
      "    GER-Bundesliga             3366 rows, 10 seasons\n",
      "    ITA-Serie A                4180 rows, 10 seasons\n",
      "\n",
      "  Dataset shape: 19,837 rows x 163 columns\n",
      "  Date range: 2014-08-08 to 2025-05-25\n",
      "\n",
      "  Sample columns in final dataset:\n",
      "               league  season   date_norm   home_team       away_team  FTHG  FTAG FTR  home_xg   away_xg     home_elo     away_elo    elo_diff  B365H  B365D  B365A\n",
      "0  ENG-Premier League    1415  2014-08-16     Arsenal  Crystal Palace   2.0   1.0   H  1.55411  0.158151  1865.238892  1626.998047  238.240845   1.25    6.5   15.0\n",
      "1  ENG-Premier League    1415  2014-08-16   Leicester         Everton   2.0   2.0   D  1.27830  0.613273  1639.408813  1828.431274 -189.022461   3.20    3.4    2.4\n",
      "2  ENG-Premier League    1415  2014-08-16  Man United         Swansea   1.0   2.0   A  1.16635  0.278076  1858.599121  1672.918579  185.680542   1.36    5.0   11.0\n",
      "\n",
      "============================================================\n",
      "  VALIDATION PASSED -- All key columns below 5% missing data.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 5: Validation & Quality Checks\n",
    "# =============================================================================\n",
    "\n",
    "print('MASTER DATASET VALIDATION')\n",
    "print('=' * 60)\n",
    "\n",
    "# --- Key columns to validate ---\n",
    "key_cols = ['home_xg', 'away_xg', 'home_elo', 'away_elo', 'elo_diff']\n",
    "threshold = 0.05  # 5% max missing\n",
    "\n",
    "print(f'\\n  Missingness check (threshold: <{threshold*100:.0f}%):')\n",
    "all_pass = True\n",
    "for col in key_cols:\n",
    "    if col in merged.columns:\n",
    "        missing = merged[col].isna().sum()\n",
    "        pct = missing / len(merged)\n",
    "        passed = pct < threshold\n",
    "        status = '[PASS]' if passed else '[FAIL]'\n",
    "        if not passed:\n",
    "            all_pass = False\n",
    "        print(f'    {status} {col:15s} {missing:>6} missing ({pct*100:.2f}%)')\n",
    "    else:\n",
    "        print(f'    [FAIL] {col:15s} COLUMN NOT FOUND')\n",
    "        all_pass = False\n",
    "\n",
    "# --- League coverage ---\n",
    "print(f'\\n  League coverage:')\n",
    "for league in sorted(merged['league'].unique()):\n",
    "    mask = merged['league'] == league\n",
    "    rows = mask.sum()\n",
    "    seasons = merged.loc[mask, 'season'].nunique()\n",
    "    print(f'    {league:25s} {rows:>5} rows, {seasons:>2} seasons')\n",
    "\n",
    "# --- Shape summary ---\n",
    "print(f'\\n  Dataset shape: {merged.shape[0]:,} rows x {merged.shape[1]} columns')\n",
    "print(f'  Date range: {merged[\"date_norm\"].min()} to {merged[\"date_norm\"].max()}')\n",
    "\n",
    "# --- Sample output ---\n",
    "print(f'\\n  Sample columns in final dataset:')\n",
    "sample_cols = ['league', 'season', 'date_norm', 'home_team', 'away_team',\n",
    "               'FTHG', 'FTAG', 'FTR', 'home_xg', 'away_xg',\n",
    "               'home_elo', 'away_elo', 'elo_diff', 'B365H', 'B365D', 'B365A']\n",
    "available = [c for c in sample_cols if c in merged.columns]\n",
    "print(merged[available].head(3).to_string())\n",
    "\n",
    "# --- Final verdict ---\n",
    "print(f'\\n{\"=\" * 60}')\n",
    "if all_pass:\n",
    "    print('  VALIDATION PASSED -- All key columns below 5% missing data.')\n",
    "else:\n",
    "    print('  VALIDATION FAILED -- Some columns exceed 5% missing threshold.')\n",
    "    print('  Review the mapping dictionaries and re-run.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master Training Set saved:\n",
      "  Path:    c:\\Users\\ljega\\Downloads\\MSBA\\Sports Analytics Project\\data\\processed\\Master_Training_Set.csv\n",
      "  Rows:    19,837\n",
      "  Columns: 163\n",
      "  Size:    11.4 MB\n",
      "\n",
      "Phase 2 complete. Ready for model training.\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# Cell 6: Save Master Training Set\n",
    "# =============================================================================\n",
    "\n",
    "output_path = os.path.join(processed_dir, 'Master_Training_Set.csv')\n",
    "\n",
    "# --- Drop the temporary date_norm if we want to keep original date ---\n",
    "# Keep date_norm as it is cleaner for downstream use\n",
    "merged.to_csv(output_path, index=False)\n",
    "\n",
    "size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "print(f'Master Training Set saved:')\n",
    "print(f'  Path:    {os.path.abspath(output_path)}')\n",
    "print(f'  Rows:    {len(merged):,}')\n",
    "print(f'  Columns: {merged.shape[1]}')\n",
    "print(f'  Size:    {size_mb:.1f} MB')\n",
    "print(f'\\nPhase 2 complete. Ready for model training.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}